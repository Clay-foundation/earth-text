{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea68431d-854a-48d8-ad2e-b11fb1738d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clay model repo on branch clay-v0.2-run\n",
    "# https://github.com/Clay-foundation/model/tree/clay-v0.2-run\n",
    "CLAY_MODEL_SRC = \"../../../model\"\n",
    "CKPT_PATH = \"/opt/data/models/clay-model-v0.2-last.ckpt\"\n",
    "import sys; sys.path.append(CLAY_MODEL_SRC)\n",
    "from src.model_clay import CLAYModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd13cb-9ea6-430a-a8b7-910f61316e2b",
   "metadata": {},
   "source": [
    "# check we are in correct branch\n",
    "\n",
    "clay model repo on branch `clay-v0.2-run` https://github.com/Clay-foundation/model/tree/clay-v0.2-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fe5732-0d05-4dab-b17d-49107f6bf8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/model\n",
      "/home/ubuntu/earth-text/notebooks/models\n"
     ]
    }
   ],
   "source": [
    "pwd = !pwd\n",
    "pwd=pwd[0]\n",
    "%cd $CLAY_MODEL_SRC\n",
    "clayrepo_branch = !git rev-parse --abbrev-ref HEAD\n",
    "clayrepo_branch = clayrepo_branch[0]\n",
    "%cd $pwd\n",
    "clay_repo_branch = 'clay-v0.2-run'\n",
    "if clayrepo_branch != clay_repo_branch:\n",
    "    raise ValueError(f\"must switch to branch {clay_repo_branch} on clay model repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1b949-b657-4918-ab54-858ea9d7fc06",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffbfe93-0121-47c5-9f79-740bf94c599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5c1f75-c758-49d7-8ec8-e4216249fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/earth-text-env/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['model.encoder.patch_embedding.rededge.proj.weight', 'model.encoder.patch_embedding.rededge.proj.bias', 'model.encoder.patch_embedding.rededge.norm.weight', 'model.encoder.patch_embedding.rededge.norm.bias', 'model.encoder.patch_embedding.swir.proj.weight', 'model.encoder.patch_embedding.swir.proj.bias', 'model.encoder.patch_embedding.swir.norm.weight', 'model.encoder.patch_embedding.swir.norm.bias', 'model.encoder.patch_embedding.dem.proj.weight', 'model.encoder.patch_embedding.dem.proj.bias', 'model.encoder.patch_embedding.dem.norm.weight', 'model.encoder.patch_embedding.dem.norm.bias', 'model.decoder.embed_to_pixels.rededge.weight', 'model.decoder.embed_to_pixels.rededge.bias', 'model.decoder.embed_to_pixels.swir.weight', 'model.decoder.embed_to_pixels.swir.bias', 'model.decoder.embed_to_pixels.dem.weight', 'model.decoder.embed_to_pixels.dem.bias']\n"
     ]
    }
   ],
   "source": [
    "CKPT_PATH = \"/opt/data/models/clay-model-v0.2-last.ckpt\"\n",
    "\n",
    "m = CLAYModule.load_from_checkpoint(\n",
    "    CKPT_PATH,\n",
    "    mask_ratio=0.0,\n",
    "    #band_groups={\"rgb\": (2, 1, 0)},\n",
    "    #band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,)},\n",
    "    band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,), \"sar\": (4,5)},\n",
    "    #band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,), \"sar\": (4,5), 'rededge': (6,7,8,9)},\n",
    "    bands=4,\n",
    "    strict=False,  # ignore the extra parameters in the checkpoint\n",
    "    embeddings_level=\"mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28c9fd-7f1f-4e33-8d95-c004a569104a",
   "metadata": {},
   "source": [
    "# loop over all files batching them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe5e3c6-ee6f-4de3-ba0c-724d75c468cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;255;0;0m  0%\u001b[39m \u001b[38;2;255;0;0m(0 of 6982)\u001b[39m |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.094218492507935\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "from progressbar import progressbar as pbar\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "basedir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/chips\"\n",
    "embeddings_dir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/embeddings_v0.2\"\n",
    "patch_embeddings_dir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/patch_embeddings_v0.2\"\n",
    "files = os.listdir(basedir)\n",
    "\n",
    "batch_size = 16\n",
    "batch = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "for batchnb in pbar(range(0,len(files),batch_size)):\n",
    "\n",
    "    # load btch of images\n",
    "    files = files[batchnb*batch_size:(batchnb+1)*batch_size]\n",
    "    for fname in files:\n",
    "        \n",
    "        with xr.open_dataarray(f\"{basedir}/{fname}\") as z:\n",
    "            img = z.data.copy()\n",
    "        batch.append(img)\n",
    "\n",
    "    # prepare data structure for model\n",
    "    z = { 'pixels': torch.tensor(np.r_[batch]),\n",
    "          'timestep': torch.tensor([[0., 0., 0.]] * batch_size),\n",
    "          'latlon': torch.tensor([[0.,0.]] * batch_size)\n",
    "        }\n",
    "\n",
    "    # run model\n",
    "    embeddings_raw, _, _, _ =  m.model.encoder(z)\n",
    "\n",
    "    # compute patch and image embeddings\n",
    "    patch_embeddings_per_group = rearrange(\n",
    "        embeddings_raw[:, :-2, :], \"b (g h w) d -> b g h w d\", w=16, h=16, g=len(self.model.band_groups)\n",
    "    )\n",
    "    patch_embeddings = reduce(\n",
    "        patch_embeddings_per_group, \"b g h w d -> b h w d\", \"mean\"\n",
    "    )\n",
    "    image_embeddings = reduce(\n",
    "        patch_embeddings, \"b h w d -> b d\", \"mean\"\n",
    "    )\n",
    "\n",
    "    # save embeddings\n",
    "    for fname in files:\n",
    "        dest_fname = fname.split(\".\")[0]+\".pkl\"\n",
    "    \n",
    "        with open(f\"{patch_embeddings_dir}/{dest_fname}\", \"wb\") as f:\n",
    "            pickle.dump(patch_embeddings.cpu().detach().numpy(), f)\n",
    "            \n",
    "        with open(f\"{embeddings_dir}/{dest_fname}\", \"wb\") as f:\n",
    "            pickle.dump(image_embeddings.cpu().detach().numpy(), f)\n",
    "    break\n",
    "    \n",
    "t1 = time()\n",
    "print (t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6111dc7-04ea-4b68-b184-2e38f7c8b57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a199e1-02f1-4ada-8220-2bb4c4dd7698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6daae56-342f-4e9e-885e-e74dd3e8f864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5a9a1-716f-461a-9205-aacc29275a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53796d97-a576-4669-b872-bb9fa0f4c9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b9ab4-ba38-475a-96c7-fd76fc873c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc664e-8a6f-47fb-88a0-e7c504a4eb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2fe76c-f4bf-4e2d-8f1d-c3324c08fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random generation of data\n",
    "nbands = len([i for j in m.model.band_groups.values() for i in j])\n",
    "z = { 'pixels': torch.rand((batch_size,nbands,256,256)),\n",
    "      'timestep': torch.tensor([[0., 0., 0.]] * batch_size),\n",
    "      'latlon': torch.tensor([[-124.,43.]] * batch_size)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf235-a9f5-4199-863d-62eccf67a459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-text-env",
   "language": "python",
   "name": "earth-text-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
