{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea68431d-854a-48d8-ad2e-b11fb1738d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clay model repo on branch clay-v0.2-run\n",
    "# https://github.com/Clay-foundation/model/tree/clay-v0.2-run\n",
    "CLAY_MODEL_SRC = \"../../../model\"\n",
    "CKPT_PATH = \"/opt/data/models/clay-model-v0.2-last.ckpt\"\n",
    "import sys; sys.path.append(CLAY_MODEL_SRC)\n",
    "from src.model_clay import CLAYModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd13cb-9ea6-430a-a8b7-910f61316e2b",
   "metadata": {},
   "source": [
    "# check we are in correct branch\n",
    "\n",
    "clay model repo on branch `clay-v0.2-run` https://github.com/Clay-foundation/model/tree/clay-v0.2-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fe5732-0d05-4dab-b17d-49107f6bf8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/model\n",
      "/home/ubuntu/earth-text/notebooks/models\n"
     ]
    }
   ],
   "source": [
    "pwd = !pwd\n",
    "pwd=pwd[0]\n",
    "%cd $CLAY_MODEL_SRC\n",
    "clayrepo_branch = !git rev-parse --abbrev-ref HEAD\n",
    "clayrepo_branch = clayrepo_branch[0]\n",
    "%cd $pwd\n",
    "clay_repo_branch = 'clay-v0.2-run'\n",
    "if clayrepo_branch != clay_repo_branch:\n",
    "    raise ValueError(f\"must switch to branch {clay_repo_branch} on clay model repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1b949-b657-4918-ab54-858ea9d7fc06",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffbfe93-0121-47c5-9f79-740bf94c599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5c1f75-c758-49d7-8ec8-e4216249fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['model.encoder.patch_embedding.rededge.proj.weight', 'model.encoder.patch_embedding.rededge.proj.bias', 'model.encoder.patch_embedding.rededge.norm.weight', 'model.encoder.patch_embedding.rededge.norm.bias', 'model.encoder.patch_embedding.swir.proj.weight', 'model.encoder.patch_embedding.swir.proj.bias', 'model.encoder.patch_embedding.swir.norm.weight', 'model.encoder.patch_embedding.swir.norm.bias', 'model.encoder.patch_embedding.dem.proj.weight', 'model.encoder.patch_embedding.dem.proj.bias', 'model.encoder.patch_embedding.dem.norm.weight', 'model.encoder.patch_embedding.dem.norm.bias', 'model.decoder.embed_to_pixels.rededge.weight', 'model.decoder.embed_to_pixels.rededge.bias', 'model.decoder.embed_to_pixels.swir.weight', 'model.decoder.embed_to_pixels.swir.bias', 'model.decoder.embed_to_pixels.dem.weight', 'model.decoder.embed_to_pixels.dem.bias']\n"
     ]
    }
   ],
   "source": [
    "CKPT_PATH = \"/opt/data/models/clay-model-v0.2-last.ckpt\"\n",
    "\n",
    "m = CLAYModule.load_from_checkpoint(\n",
    "    CKPT_PATH,\n",
    "    mask_ratio=0.0,\n",
    "    #band_groups={\"rgb\": (2, 1, 0)},\n",
    "    #band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,)},\n",
    "    band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,), \"sar\": (4,5)},\n",
    "    #band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,), \"sar\": (4,5), 'rededge': (6,7,8,9)},\n",
    "    bands=4,\n",
    "    strict=False,  # ignore the extra parameters in the checkpoint\n",
    "    embeddings_level=\"mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28c9fd-7f1f-4e33-8d95-c004a569104a",
   "metadata": {},
   "source": [
    "# loop over all files batching them and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfe5e3c6-ee6f-4de3-ba0c-724d75c468cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(55850 of 55850)\u001b[39m |##################| Elapsed Time: 1:00:15 Time:  1:00:152955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3615.498753786087\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "from progressbar import progressbar as pbar\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "basedir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/chips\"\n",
    "embeddings_dir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/embeddings_v0.2\"\n",
    "patch_embeddings_dir = \"/opt/data/clay-california-worldcover-rgbnir-vvvh-chips/patch_embeddings_v0.2\"\n",
    "files = os.listdir(basedir)\n",
    "\n",
    "batch_size = 2\n",
    "batch = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "for batchnb in pbar(range(0,len(files),batch_size)):\n",
    "\n",
    "    # load btch of images\n",
    "    batchfiles = files[batchnb:batchnb+batch_size]\n",
    "    batch = []\n",
    "    for fname in batchfiles:\n",
    "        \n",
    "        with xr.open_dataarray(f\"{basedir}/{fname}\") as z:\n",
    "            img = z.data.copy()\n",
    "        batch.append(img)\n",
    "\n",
    "    # prepare data structure for model\n",
    "    z = { 'pixels': torch.tensor(np.r_[batch]).cuda(),\n",
    "          'timestep': torch.tensor([[0., 0., 0.]] * batch_size).cuda(),\n",
    "          'latlon': torch.tensor([[0.,0.]] * batch_size).cuda()\n",
    "        }\n",
    "\n",
    "    # run model\n",
    "    embeddings_raw, _, _, _ =  m.model.encoder(z)\n",
    "\n",
    "    # compute patch and image embeddings\n",
    "    patch_embeddings_per_group = rearrange(\n",
    "        embeddings_raw[:, :-2, :], \"b (g h w) d -> b g h w d\", w=16, h=16, g=len(m.model.band_groups)\n",
    "    )\n",
    "    patch_embeddings = reduce(\n",
    "        patch_embeddings_per_group, \"b g h w d -> b h w d\", \"mean\"\n",
    "    )\n",
    "    image_embeddings = reduce(\n",
    "        patch_embeddings, \"b h w d -> b d\", \"mean\"\n",
    "    )\n",
    "\n",
    "    # save embeddings\n",
    "    for i,fname in enumerate(batchfiles):\n",
    "        dest_fname = fname.split(\".\")[0]+\".pkl\"\n",
    "        #print (batchnb, i, dest_fname)\n",
    "        with open(f\"{patch_embeddings_dir}/{dest_fname}\", \"wb\") as f:\n",
    "            pickle.dump(patch_embeddings[i].cpu().detach().numpy(), f)\n",
    "            \n",
    "        with open(f\"{embeddings_dir}/{dest_fname}\", \"wb\") as f:\n",
    "            pickle.dump(image_embeddings[i].cpu().detach().numpy(), f)\n",
    "\n",
    "    # empty cuda memory\n",
    "    del image_embeddings\n",
    "    del patch_embeddings\n",
    "    del patch_embeddings_per_group\n",
    "    del z\n",
    "    torch.cuda.empty_cache()\n",
    "    #if batchnb>10:\n",
    "    #    break\n",
    "t1 = time()\n",
    "print (t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b9ab4-ba38-475a-96c7-fd76fc873c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc664e-8a6f-47fb-88a0-e7c504a4eb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2fe76c-f4bf-4e2d-8f1d-c3324c08fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random generation of data\n",
    "nbands = len([i for j in m.model.band_groups.values() for i in j])\n",
    "z = { 'pixels': torch.rand((batch_size,nbands,256,256)),\n",
    "      'timestep': torch.tensor([[0., 0., 0.]] * batch_size),\n",
    "      'latlon': torch.tensor([[-124.,43.]] * batch_size)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf235-a9f5-4199-863d-62eccf67a459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
